{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noushsuon/honours-project/blob/edit-carbon-configuration/NoPretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet-ml\n",
        "!pip install cumulator\n",
        "!pip install geopy\n",
        "!pip install GPUtil\n",
        "!pip install py-cpuinfo\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install accelerate -U\n",
        "!pip install codecarbon\n",
        "!pip install transformers\n",
        "!pip install tokenizers"
      ],
      "metadata": {
        "id": "syptDmz1J3ys"
      },
      "id": "syptDmz1J3ys",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "dc830f96003a4801a571b0752a571376",
            "7e65103e979440779408089b600c7d8e",
            "7adf6cba500a42f69da4c65b09edaa88",
            "97342f20101a4680adfcbe475b07094c",
            "ccfdb40506cb4088addfc4ac85a7e9f3",
            "650976b77f0748578d57351a03857f0d",
            "1aa06dcace3345ea9f892b5a7f6fd676",
            "3e337e209c914018838269dcfbe70f5b",
            "618d0fe8ff38410996e259da236995c7",
            "2d59618622fa46f3a04984adf84aba4a",
            "6767bb2f358c461ca28d456434499bda",
            "7f3d09f203e54ddab5b42ef18fbd7a44",
            "3f54bfec11804ba187edc7274508fb34",
            "aba9a497813947e3a04ba63cac9d9cd4",
            "3f78d60b76e447d384090c0df459dbdf",
            "a61980996b7e40dfbb12417289ba6aee",
            "a193cc403e8e4838aedfef3ec1dea15e",
            "cc5e9512dbc7472b979ec72f37e50d82",
            "4c0230e4a8714e46bb0d3a6de99f355d",
            "93414c8a2dc54c8fa1471c1ced4df716",
            "90a62df70c2d43c4b39c610d734cadb5",
            "d21f8f3689ff47d1b8649c504c47fb15",
            "47af879a7b01421590211561f8bb39bd",
            "17885cd373c64cfa8010894bd6fc7b54",
            "9a06672a36a4419a86c2a17616a1cd60",
            "d4b2d18650814ce69405b6e7aebfd618",
            "fc67173be16843a7b51ddfa40db395be",
            "3fcd6cf09b634d588a1160d07e7b4385",
            "3ab661f346b944ef8ffa2c4491911c92",
            "6fc5555120ca4c9e9796b630a2ba4192",
            "b46e1b7d44c740c0a484bbbcc9ec9c4c",
            "189272fae1a248a8a6d1f09515cf598a"
          ]
        },
        "id": "M08iL4ctqCQJ",
        "outputId": "9275108b-dc67-4335-f407-cb32185bf37b"
      },
      "id": "M08iL4ctqCQJ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc830f96003a4801a571b0752a571376"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import comet_ml\n",
        "from comet_ml import Experiment\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "import csv\n",
        "hardwareFile = \"/usr/local/lib/python3.10/dist-packages/codecarbon/data/hardware/cpu_power.csv\"\n",
        "cpu_data = ['13th Gen Intel(R) Core(TM) i9-13950HX', 55]\n",
        "with open(hardwareFile, 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(cpu_data)\n",
        "\n",
        "comet_ml.init(api_key='uyaIbaxDfy7jK9j7u4KNxeKNg',project_name='comet-bert-experiment')\n",
        "experiment = comet_ml.Experiment(api_key=\"uyaIbaxDfy7jK9j7u4KNxeKNg\",project_name=\"comet-bert-experiment\",)"
      ],
      "metadata": {
        "id": "53dVvPnboKW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb9cadb-375f-4c9c-8afa-c2bf0e70066c"
      },
      "id": "53dVvPnboKW4",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "[codecarbon INFO @ 18:06:14] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 18:06:14] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 18:06:14] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 18:06:14] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 18:06:14] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 18:06:16] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i9-13950HX\n",
            "[codecarbon INFO @ 18:06:16] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 18:06:16]   Platform system: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 18:06:16]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 18:06:16]   CodeCarbon version: 2.3.5\n",
            "[codecarbon INFO @ 18:06:16]   Available RAM : 15.439 GB\n",
            "[codecarbon INFO @ 18:06:16]   CPU count: 32\n",
            "[codecarbon INFO @ 18:06:16]   CPU model: 13th Gen Intel(R) Core(TM) i9-13950HX\n",
            "[codecarbon INFO @ 18:06:16]   GPU count: 1\n",
            "[codecarbon INFO @ 18:06:16]   GPU model: 1 x NVIDIA GeForce RTX 4090 Laptop GPU\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/noushsuon/comet-bert-experiment/d5ae32b0587f4853b513d1b108ed07cb\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "hardwareFile = \"/usr/local/lib/python3.10/dist-packages/cumulator/hardware_data/cpu.csv\"\n",
        "cpu_data = ['Core i9-13950HX', 'Raptor Lake-HX', '1 / 23','2.2 to 5.5 GHz','BGA 1964 ','10 nm', '36 MB', '55 W', 55]\n",
        "with open(hardwareFile, 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(cpu_data)"
      ],
      "metadata": {
        "id": "OJ4-DGSbwJ6I"
      },
      "id": "OJ4-DGSbwJ6I",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseFile = \"/usr/local/lib/python3.10/dist-packages/cumulator/base.py\"\n",
        "with open(baseFile, 'r') as file:\n",
        "        content = file.read()\n",
        "with open(baseFile, 'w') as file:\n",
        "        file.write(content.replace(\"src.cumulator\", \"cumulator\"))\n",
        "from cumulator import base\n",
        "cumulator = base.Cumulator()\n",
        "cumulator.on()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kisUK9ZwHY5",
        "outputId": "80c46a75-e91d-485e-8fca-ee7a2e258f75"
      },
      "id": "6kisUK9ZwHY5",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU recognized: TDP set to 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7e883bd4-4d0b-4f32-b05e-b585028f6b75",
      "metadata": {
        "id": "7e883bd4-4d0b-4f32-b05e-b585028f6b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504c732c-405d-4463-90fe-4d28d5f8e123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import transformers\n",
        "\n",
        "raw_datasets = load_dataset(\"squad\")\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "import os\n",
        "combined_data = [context + \" \" + question for context, question in zip(raw_datasets['train']['context'], raw_datasets['train']['question'])]\n",
        "tokenizer = BertWordPieceTokenizer(clean_text=True,lowercase=False,handle_chinese_chars=False)\n",
        "tokenizer.train_from_iterator(combined_data, length=512, special_tokens=[\"[UNK]\", \"[SEP]\", \"[CLS]\", \"[PAD]\", \"[MASK]\"])\n",
        "path = \"/content\"\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "tokenizer.save_model(path)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(path, model_max_length=512, do_lower_case=False)"
      ],
      "metadata": {
        "id": "TYdzjLokVc_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156b0113-b3d8-48a6-b23f-ee5f2a77e73a"
      },
      "id": "TYdzjLokVc_9",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 18:06:31] Energy consumed for RAM : 0.000024 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:06:31] Energy consumed for all GPUs : 0.000119 kWh. Total GPU Power : 28.431377089593916 W\n",
            "[codecarbon INFO @ 18:06:31] Energy consumed for all CPUs : 0.000115 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:06:31] 0.000257 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:06:46] Energy consumed for RAM : 0.000048 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:06:46] Energy consumed for all GPUs : 0.000198 kWh. Total GPU Power : 19.15501366730228 W\n",
            "[codecarbon INFO @ 18:06:46] Energy consumed for all CPUs : 0.000232 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:06:46] 0.000479 kWh of electricity used since the beginning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyxDq2Dagld5",
        "outputId": "9a139dd8-f082-4418-9516-bc15683ff593"
      },
      "id": "RyxDq2Dagld5",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertTokenizerFast(name_or_path='/content', vocab_size=30000, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t3: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = raw_datasets[\"train\"][1902][\"context\"]\n",
        "question = raw_datasets[\"train\"][1902][\"question\"]\n",
        "\n",
        "inputs = tokenizer(question, context)\n",
        "tokenizer.decode(inputs[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "FONyPjQU9js8",
        "outputId": "46575db6-e11a-47f6-dced-19efc503bc5a"
      },
      "id": "FONyPjQU9js8",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] What television station made a documentary on Chopin? [SEP] Chopin's life was covered in a BBC TV documentary Chopin – The Women Behind The Music ( 2010 ), and in a 2010 documentary realised by Angelo Bozzolini and Roberto Prosseda for Italian television. [SEP]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "74d933c4-8d0b-4867-a171-ed7bfd5d7ab1",
      "metadata": {
        "id": "74d933c4-8d0b-4867-a171-ed7bfd5d7ab1"
      },
      "outputs": [],
      "source": [
        "max_length = 384\n",
        "stride = 128\n",
        "\n",
        "\n",
        "def preprocess_training_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\", #only truncates the context\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True, #model will store strings ignored when truncating\n",
        "        return_offsets_mapping=True, #stores the location of tokens in original text\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        sample_idx = sample_map[i]\n",
        "        answer = answers[sample_idx]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label is (0, 0)\n",
        "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9e2e3ab8-3185-469f-8c07-6cb1a142cd17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "2e262e17666147aebd4731e391cfcbde",
            "c6b0a6d43f214d589470c43d20b0ecd6",
            "2dab8c5fa2b74875b0171c69fbabdd80",
            "04ef4c9dd0064c50962f40f332fb571e",
            "9e5fb55c2f044a33b15241e15cc9c2a4",
            "398c855f74b64eb884bc3ecacf02145f",
            "ae09a1d8d10e40ab988ec43c7da930ce",
            "acad1940248e43e788d3edf8136d031a",
            "4e6b7cb3a70340618bcd640f68902af3",
            "b1fd21b234d340979cecc0751984deeb",
            "c62c134d40eb45459d1878fd5d703c3d"
          ]
        },
        "id": "9e2e3ab8-3185-469f-8c07-6cb1a142cd17",
        "outputId": "df1db606-f9d3-48be-ac9b-4370d7ac48d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e262e17666147aebd4731e391cfcbde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 18:07:01] Energy consumed for RAM : 0.000072 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:07:01] Energy consumed for all GPUs : 0.000290 kWh. Total GPU Power : 22.65500400493134 W\n",
            "[codecarbon INFO @ 18:07:01] Energy consumed for all CPUs : 0.000348 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:07:01] 0.000710 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87599, 88518)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#use previously defined function to preprocess training data\n",
        "train_dataset = raw_datasets[\"train\"].map(\n",
        "    preprocess_training_examples,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")\n",
        "len(raw_datasets[\"train\"]), len(train_dataset) #check the sentences have been tokenised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cb52571e-ed89-413c-b034-2e51621d223d",
      "metadata": {
        "id": "cb52571e-ed89-413c-b034-2e51621d223d"
      },
      "outputs": [],
      "source": [
        "#similar to training data but with simplified offset mapping, use of example ids and not the start and end positions,\n",
        "def preprocess_validation_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    example_ids = []\n",
        "\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        sample_idx = sample_map[i]\n",
        "        example_ids.append(examples[\"id\"][sample_idx])\n",
        "\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        offset = inputs[\"offset_mapping\"][i]\n",
        "        inputs[\"offset_mapping\"][i] = [\n",
        "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
        "        ]\n",
        "\n",
        "    inputs[\"example_id\"] = example_ids\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7a69f322-fcf7-4923-900b-69d3f9b5c3d4",
      "metadata": {
        "id": "7a69f322-fcf7-4923-900b-69d3f9b5c3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "f2e7efd8de30429eb9da4bfe99d62d2e",
            "210416c6a771448fbb0a8bf2bcb86436",
            "1016fe89187944db914f82c742e49409",
            "ed14e8cf3e0c42ad921e740a2ef82637",
            "1615915542444c24ac0c9f25a2540297",
            "11c24520e5e34ae29fcc8d79d9be5410",
            "d7cd1949f78f47cf859f0a2a65e36989",
            "872d386ea4f84b86b39b4b854c90ab0a",
            "587beabd25734baf8cdbc1c73e152595",
            "5ab51f3d150d4eafa38d731c0ff61f39",
            "e301d552b438487abac84e49a059dcf4"
          ]
        },
        "outputId": "ecb33cde-d2f5-4cd5-c9ff-97506834574d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2e7efd8de30429eb9da4bfe99d62d2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10570, 10792)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#use function to preprocess validation data\n",
        "validation_dataset = raw_datasets[\"validation\"].map(\n",
        "    preprocess_validation_examples,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
        ")\n",
        "len(raw_datasets[\"validation\"]), len(validation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8e4ded6-51e8-4d7d-9628-1317859043f3",
      "metadata": {
        "id": "c8e4ded6-51e8-4d7d-9628-1317859043f3"
      },
      "source": [
        "post processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialise new/untrained model\n",
        "from transformers import BertConfig, BertForQuestionAnswering\n",
        "config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
        "config.vocab_size = len(tokenizer)\n",
        "model = BertForQuestionAnswering(config)\n"
      ],
      "metadata": {
        "id": "a4qh6UB9yugw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c761c2-1442-450b-fd81-1e25ca2d8b39"
      },
      "id": "a4qh6UB9yugw",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 18:07:16] Energy consumed for RAM : 0.000095 kWh. RAM Power : 5.789747714996338 W\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "n_best = 20\n",
        "max_answer_length = 30\n",
        "predicted_answers = []\n",
        "\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"squad\")\n",
        "\n",
        "def get_example(index):\n",
        "    return tokenized_datasets[\"test\"][index][\"text\"]\n",
        "\n",
        "def compute_metrics(start_logits, end_logits, features, examples):\n",
        "    experiment = comet_ml.get_global_experiment()\n",
        "    example_to_features = collections.defaultdict(list)\n",
        "\n",
        "    for idx, feature in enumerate(features):\n",
        "        example_to_features[feature[\"example_id\"]].append(idx)\n",
        "\n",
        "    predicted_answers = []\n",
        "\n",
        "    for example in tqdm(examples):\n",
        "        example_id = example[\"id\"]\n",
        "        context = example[\"context\"]\n",
        "        answers = []\n",
        "\n",
        "        # Loop through all features associated with that example\n",
        "        for feature_index in example_to_features[example_id]:\n",
        "            start_logit = start_logits[feature_index]\n",
        "            end_logit = end_logits[feature_index]\n",
        "            offsets = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Skip answers that are not fully in the context\n",
        "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
        "                        continue\n",
        "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
        "                    if (\n",
        "                        end_index < start_index\n",
        "                        or end_index - start_index + 1 > max_answer_length\n",
        "                    ):\n",
        "                        continue\n",
        "\n",
        "                    answer = {\n",
        "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
        "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
        "                    }\n",
        "                    answers.append(answer)\n",
        "\n",
        "        # Select the answer with the best score\n",
        "        if len(answers) > 0:\n",
        "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
        "            predicted_answers.append(\n",
        "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
        "            )\n",
        "        else:\n",
        "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
        "\n",
        "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
        "    metric_result = metric.compute(predictions=predicted_answers, references=theoretical_answers)\n",
        "    if experiment:\n",
        "        experiment.log_metric(\"f1\", metric_result['f1'])\n",
        "        experiment.log_metric(\"exact_match\", metric_result['exact_match'])\n",
        "    return metric_result"
      ],
      "metadata": {
        "id": "lvJsvBVlOnVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5258398c-3dac-4d75-8e89-88b296e0e59a"
      },
      "id": "lvJsvBVlOnVt",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 18:07:16] Energy consumed for all GPUs : 0.000373 kWh. Total GPU Power : 20.57780207224324 W\n",
            "[codecarbon INFO @ 18:07:16] Energy consumed for all CPUs : 0.000461 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:07:16] 0.000929 kWh of electricity used since the beginning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "V4aZdy4mpcEx"
      },
      "id": "V4aZdy4mpcEx"
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import TrainingArguments\n",
        "import accelerate\n",
        "\n",
        "%env COMET_MODE=ONLINE\n",
        "%env COMET_LOG_ASSETS=TRUE\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"no-pretraining-bert-final\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    fp16=True,\n",
        "    push_to_hub=True,\n",
        "    report_to=[\"comet_ml\"],\n",
        "    logging_strategy=\"epoch\",\n",
        "    seed=42,\n",
        "    load_best_model_at_end=False,\n",
        "    save_total_limit=1,\n",
        ")"
      ],
      "metadata": {
        "id": "SWXIiaqTOtgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4fc361-fac2-43b1-ee0a-4f30a6ae0e37"
      },
      "id": "SWXIiaqTOtgZ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: COMET_MODE=ONLINE\n",
            "env: COMET_LOG_ASSETS=TRUE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "RjDoJCYgO9EI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ba0d0ba-46e2-4887-90c9-0560bda3a76c"
      },
      "id": "RjDoJCYgO9EI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 18:07:18] Energy consumed for RAM : 0.000098 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:07:18] Energy consumed for all GPUs : 0.000396 kWh. Total GPU Power : 40.80131154506296 W\n",
            "[codecarbon INFO @ 18:07:18] Energy consumed for all CPUs : 0.000477 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:07:18] 0.000971 kWh of electricity used since the beginning.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : noisy_octopus_7668\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/noushsuon/comet-bert-experiment/d5ae32b0587f4853b513d1b108ed07cb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset               : 1 (856 bytes)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "[codecarbon INFO @ 18:07:21] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 18:07:21] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 18:07:21] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 18:07:21] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 18:07:21] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 18:07:22] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i9-13950HX\n",
            "[codecarbon INFO @ 18:07:22] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 18:07:22]   Platform system: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 18:07:22]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 18:07:22]   CodeCarbon version: 2.3.5\n",
            "[codecarbon INFO @ 18:07:22]   Available RAM : 15.439 GB\n",
            "[codecarbon INFO @ 18:07:22]   CPU count: 32\n",
            "[codecarbon INFO @ 18:07:22]   CPU model: 13th Gen Intel(R) Core(TM) i9-13950HX\n",
            "[codecarbon INFO @ 18:07:22]   GPU count: 1\n",
            "[codecarbon INFO @ 18:07:22]   GPU model: 1 x NVIDIA GeForce RTX 4090 Laptop GPU\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/noushsuon/comet-bert-experiment/3d0a9871dc67474c810af8d081907511\n",
            "\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1382' max='33195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1382/33195 18:23 < 7:03:55, 1.25 it/s, Epoch 0.12/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 18:07:37] Energy consumed for RAM : 0.000024 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:07:37] Energy consumed for all GPUs : 0.000220 kWh. Total GPU Power : 52.84855330618053 W\n",
            "[codecarbon INFO @ 18:07:37] Energy consumed for all CPUs : 0.000115 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:07:37] 0.000360 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:07:52] Energy consumed for RAM : 0.000048 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:07:52] Energy consumed for all GPUs : 0.000454 kWh. Total GPU Power : 56.299256662649725 W\n",
            "[codecarbon INFO @ 18:07:52] Energy consumed for all CPUs : 0.000230 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:07:52] 0.000732 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:08:07] Energy consumed for RAM : 0.000072 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:08:07] Energy consumed for all GPUs : 0.000688 kWh. Total GPU Power : 56.22809513602099 W\n",
            "[codecarbon INFO @ 18:08:07] Energy consumed for all CPUs : 0.000344 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:08:07] 0.001104 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:08:22] Energy consumed for RAM : 0.000096 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:08:22] Energy consumed for all GPUs : 0.000917 kWh. Total GPU Power : 55.32476094722816 W\n",
            "[codecarbon INFO @ 18:08:22] Energy consumed for all CPUs : 0.000458 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:08:22] 0.001472 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:08:37] Energy consumed for RAM : 0.000120 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:08:37] Energy consumed for all GPUs : 0.001149 kWh. Total GPU Power : 55.552067151773805 W\n",
            "[codecarbon INFO @ 18:08:37] Energy consumed for all CPUs : 0.000573 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:08:37] 0.001842 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:08:52] Energy consumed for RAM : 0.000144 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:08:52] Energy consumed for all GPUs : 0.001391 kWh. Total GPU Power : 58.225552137568386 W\n",
            "[codecarbon INFO @ 18:08:52] Energy consumed for all CPUs : 0.000688 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:08:52] 0.002223 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:09:07] Energy consumed for RAM : 0.000169 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:09:07] Energy consumed for all GPUs : 0.001630 kWh. Total GPU Power : 57.32624976467625 W\n",
            "[codecarbon INFO @ 18:09:07] Energy consumed for all CPUs : 0.000802 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:09:07] 0.002600 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:09:22] Energy consumed for RAM : 0.000193 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:09:22] Energy consumed for all GPUs : 0.001860 kWh. Total GPU Power : 55.45955298821238 W\n",
            "[codecarbon INFO @ 18:09:22] Energy consumed for all CPUs : 0.000917 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:09:22] 0.002970 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:09:37] Energy consumed for RAM : 0.000217 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:09:37] Energy consumed for all GPUs : 0.002100 kWh. Total GPU Power : 57.49658250669286 W\n",
            "[codecarbon INFO @ 18:09:37] Energy consumed for all CPUs : 0.001031 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:09:37] 0.003348 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:09:52] Energy consumed for RAM : 0.000241 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:09:52] Energy consumed for all GPUs : 0.002334 kWh. Total GPU Power : 56.16507224969058 W\n",
            "[codecarbon INFO @ 18:09:52] Energy consumed for all CPUs : 0.001146 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:09:52] 0.003721 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:10:07] Energy consumed for RAM : 0.000265 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:10:07] Energy consumed for all GPUs : 0.002570 kWh. Total GPU Power : 56.7538902436102 W\n",
            "[codecarbon INFO @ 18:10:07] Energy consumed for all CPUs : 0.001260 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:10:07] 0.004095 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:10:22] Energy consumed for RAM : 0.000289 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:10:22] Energy consumed for all GPUs : 0.002799 kWh. Total GPU Power : 54.93591578719011 W\n",
            "[codecarbon INFO @ 18:10:22] Energy consumed for all CPUs : 0.001375 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:10:22] 0.004463 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:10:37] Energy consumed for RAM : 0.000313 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:10:37] Energy consumed for all GPUs : 0.003027 kWh. Total GPU Power : 54.85360602990558 W\n",
            "[codecarbon INFO @ 18:10:37] Energy consumed for all CPUs : 0.001490 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:10:37] 0.004830 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:10:52] Energy consumed for RAM : 0.000337 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:10:52] Energy consumed for all GPUs : 0.003258 kWh. Total GPU Power : 55.3577169287639 W\n",
            "[codecarbon INFO @ 18:10:52] Energy consumed for all CPUs : 0.001604 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:10:52] 0.005199 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:11:07] Energy consumed for RAM : 0.000361 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:11:07] Energy consumed for all GPUs : 0.003486 kWh. Total GPU Power : 54.92974587650697 W\n",
            "[codecarbon INFO @ 18:11:07] Energy consumed for all CPUs : 0.001719 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:11:07] 0.005566 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:11:22] Energy consumed for RAM : 0.000385 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:11:22] Energy consumed for all GPUs : 0.003726 kWh. Total GPU Power : 57.66409241634907 W\n",
            "[codecarbon INFO @ 18:11:22] Energy consumed for all CPUs : 0.001833 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:11:22] 0.005945 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:11:37] Energy consumed for RAM : 0.000410 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:11:37] Energy consumed for all GPUs : 0.003959 kWh. Total GPU Power : 55.781671086861124 W\n",
            "[codecarbon INFO @ 18:11:37] Energy consumed for all CPUs : 0.001948 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:11:37] 0.006316 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:11:52] Energy consumed for RAM : 0.000434 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:11:52] Energy consumed for all GPUs : 0.004186 kWh. Total GPU Power : 54.54836874188179 W\n",
            "[codecarbon INFO @ 18:11:52] Energy consumed for all CPUs : 0.002062 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:11:52] 0.006682 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:12:07] Energy consumed for RAM : 0.000458 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:12:07] Energy consumed for all GPUs : 0.004420 kWh. Total GPU Power : 56.207761768919454 W\n",
            "[codecarbon INFO @ 18:12:07] Energy consumed for all CPUs : 0.002177 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:12:07] 0.007054 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:12:22] Energy consumed for RAM : 0.000482 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:12:22] Energy consumed for all GPUs : 0.004651 kWh. Total GPU Power : 55.66244094790667 W\n",
            "[codecarbon INFO @ 18:12:22] Energy consumed for all CPUs : 0.002292 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:12:22] 0.007425 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:12:37] Energy consumed for RAM : 0.000506 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:12:37] Energy consumed for all GPUs : 0.004883 kWh. Total GPU Power : 55.67331694468764 W\n",
            "[codecarbon INFO @ 18:12:37] Energy consumed for all CPUs : 0.002406 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:12:37] 0.007795 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:12:52] Energy consumed for RAM : 0.000530 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:12:52] Energy consumed for all GPUs : 0.005121 kWh. Total GPU Power : 57.19020178003569 W\n",
            "[codecarbon INFO @ 18:12:52] Energy consumed for all CPUs : 0.002521 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:12:52] 0.008172 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:13:07] Energy consumed for RAM : 0.000554 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:13:07] Energy consumed for all GPUs : 0.005357 kWh. Total GPU Power : 56.58307687104293 W\n",
            "[codecarbon INFO @ 18:13:07] Energy consumed for all CPUs : 0.002635 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:13:07] 0.008546 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:13:22] Energy consumed for RAM : 0.000578 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:13:22] Energy consumed for all GPUs : 0.005588 kWh. Total GPU Power : 55.51828890059549 W\n",
            "[codecarbon INFO @ 18:13:22] Energy consumed for all CPUs : 0.002750 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:13:22] 0.008916 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:13:37] Energy consumed for RAM : 0.000602 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:13:37] Energy consumed for all GPUs : 0.005822 kWh. Total GPU Power : 56.22135878781907 W\n",
            "[codecarbon INFO @ 18:13:37] Energy consumed for all CPUs : 0.002864 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:13:37] 0.009289 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:13:52] Energy consumed for RAM : 0.000626 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:13:52] Energy consumed for all GPUs : 0.006052 kWh. Total GPU Power : 55.25429716200273 W\n",
            "[codecarbon INFO @ 18:13:52] Energy consumed for all CPUs : 0.002979 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:13:52] 0.009657 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:14:07] Energy consumed for RAM : 0.000651 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:14:07] Energy consumed for all GPUs : 0.006292 kWh. Total GPU Power : 57.7150318346314 W\n",
            "[codecarbon INFO @ 18:14:07] Energy consumed for all CPUs : 0.003093 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:14:07] 0.010036 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:14:22] Energy consumed for RAM : 0.000675 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:14:22] Energy consumed for all GPUs : 0.006519 kWh. Total GPU Power : 54.596693524349 W\n",
            "[codecarbon INFO @ 18:14:22] Energy consumed for all CPUs : 0.003208 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:14:22] 0.010402 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:14:37] Energy consumed for RAM : 0.000699 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:14:37] Energy consumed for all GPUs : 0.006751 kWh. Total GPU Power : 55.52363429769686 W\n",
            "[codecarbon INFO @ 18:14:37] Energy consumed for all CPUs : 0.003323 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:14:37] 0.010772 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:14:52] Energy consumed for RAM : 0.000723 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:14:52] Energy consumed for all GPUs : 0.006980 kWh. Total GPU Power : 55.180814130748054 W\n",
            "[codecarbon INFO @ 18:14:52] Energy consumed for all CPUs : 0.003437 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:14:52] 0.011141 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:15:07] Energy consumed for RAM : 0.000747 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:15:07] Energy consumed for all GPUs : 0.007213 kWh. Total GPU Power : 55.95296515526758 W\n",
            "[codecarbon INFO @ 18:15:07] Energy consumed for all CPUs : 0.003552 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:15:07] 0.011512 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:15:22] Energy consumed for RAM : 0.000771 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:15:22] Energy consumed for all GPUs : 0.007445 kWh. Total GPU Power : 55.54402209673261 W\n",
            "[codecarbon INFO @ 18:15:22] Energy consumed for all CPUs : 0.003666 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:15:22] 0.011882 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:15:37] Energy consumed for RAM : 0.000795 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:15:37] Energy consumed for all GPUs : 0.007675 kWh. Total GPU Power : 55.3063768294869 W\n",
            "[codecarbon INFO @ 18:15:37] Energy consumed for all CPUs : 0.003781 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:15:37] 0.012251 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:15:52] Energy consumed for RAM : 0.000819 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:15:52] Energy consumed for all GPUs : 0.007910 kWh. Total GPU Power : 56.59498180769875 W\n",
            "[codecarbon INFO @ 18:15:52] Energy consumed for all CPUs : 0.003895 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:15:52] 0.012625 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:16:07] Energy consumed for RAM : 0.000843 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:16:07] Energy consumed for all GPUs : 0.008143 kWh. Total GPU Power : 55.77362344666729 W\n",
            "[codecarbon INFO @ 18:16:07] Energy consumed for all CPUs : 0.004010 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:16:07] 0.012996 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:16:22] Energy consumed for RAM : 0.000867 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:16:22] Energy consumed for all GPUs : 0.008371 kWh. Total GPU Power : 54.921876274344115 W\n",
            "[codecarbon INFO @ 18:16:22] Energy consumed for all CPUs : 0.004125 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:16:22] 0.013363 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:16:37] Energy consumed for RAM : 0.000892 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:16:37] Energy consumed for all GPUs : 0.008604 kWh. Total GPU Power : 55.81621001734689 W\n",
            "[codecarbon INFO @ 18:16:37] Energy consumed for all CPUs : 0.004239 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:16:37] 0.013734 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:16:52] Energy consumed for RAM : 0.000916 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:16:52] Energy consumed for all GPUs : 0.008834 kWh. Total GPU Power : 55.33408164692065 W\n",
            "[codecarbon INFO @ 18:16:52] Energy consumed for all CPUs : 0.004354 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:16:52] 0.014104 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:17:07] Energy consumed for RAM : 0.000940 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:17:07] Energy consumed for all GPUs : 0.009071 kWh. Total GPU Power : 56.90689291488581 W\n",
            "[codecarbon INFO @ 18:17:07] Energy consumed for all CPUs : 0.004469 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:17:07] 0.014479 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:17:22] Energy consumed for RAM : 0.000964 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:17:22] Energy consumed for all GPUs : 0.009309 kWh. Total GPU Power : 57.326732530388796 W\n",
            "[codecarbon INFO @ 18:17:22] Energy consumed for all CPUs : 0.004583 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:17:22] 0.014856 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:17:37] Energy consumed for RAM : 0.000988 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:17:37] Energy consumed for all GPUs : 0.009541 kWh. Total GPU Power : 55.821953113607314 W\n",
            "[codecarbon INFO @ 18:17:37] Energy consumed for all CPUs : 0.004697 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:17:37] 0.015226 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:17:52] Energy consumed for RAM : 0.001012 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:17:52] Energy consumed for all GPUs : 0.009768 kWh. Total GPU Power : 54.5232367669492 W\n",
            "[codecarbon INFO @ 18:17:52] Energy consumed for all CPUs : 0.004812 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:17:52] 0.015592 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:18:07] Energy consumed for RAM : 0.001036 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:18:07] Energy consumed for all GPUs : 0.010001 kWh. Total GPU Power : 56.13746449313203 W\n",
            "[codecarbon INFO @ 18:18:07] Energy consumed for all CPUs : 0.004927 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:18:07] 0.015964 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:18:22] Energy consumed for RAM : 0.001060 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:18:22] Energy consumed for all GPUs : 0.010232 kWh. Total GPU Power : 55.35285930052175 W\n",
            "[codecarbon INFO @ 18:18:22] Energy consumed for all CPUs : 0.005041 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:18:22] 0.016333 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:18:37] Energy consumed for RAM : 0.001084 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:18:37] Energy consumed for all GPUs : 0.010482 kWh. Total GPU Power : 60.16405206185259 W\n",
            "[codecarbon INFO @ 18:18:37] Energy consumed for all CPUs : 0.005156 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:18:37] 0.016723 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:18:52] Energy consumed for RAM : 0.001108 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:18:52] Energy consumed for all GPUs : 0.010713 kWh. Total GPU Power : 55.457320467933144 W\n",
            "[codecarbon INFO @ 18:18:52] Energy consumed for all CPUs : 0.005270 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:18:52] 0.017091 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:19:07] Energy consumed for RAM : 0.001132 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:19:07] Energy consumed for all GPUs : 0.010947 kWh. Total GPU Power : 56.19958889512682 W\n",
            "[codecarbon INFO @ 18:19:07] Energy consumed for all CPUs : 0.005385 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:19:07] 0.017464 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:19:22] Energy consumed for RAM : 0.001157 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:19:22] Energy consumed for all GPUs : 0.011176 kWh. Total GPU Power : 54.99475585491586 W\n",
            "[codecarbon INFO @ 18:19:22] Energy consumed for all CPUs : 0.005499 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:19:22] 0.017832 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:19:37] Energy consumed for RAM : 0.001181 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:19:37] Energy consumed for all GPUs : 0.011412 kWh. Total GPU Power : 56.65433456654449 W\n",
            "[codecarbon INFO @ 18:19:37] Energy consumed for all CPUs : 0.005614 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:19:37] 0.018206 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:19:52] Energy consumed for RAM : 0.001205 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:19:52] Energy consumed for all GPUs : 0.011645 kWh. Total GPU Power : 56.104366137611756 W\n",
            "[codecarbon INFO @ 18:19:52] Energy consumed for all CPUs : 0.005729 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:19:52] 0.018579 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:20:07] Energy consumed for RAM : 0.001229 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:20:07] Energy consumed for all GPUs : 0.011875 kWh. Total GPU Power : 55.252296482842084 W\n",
            "[codecarbon INFO @ 18:20:07] Energy consumed for all CPUs : 0.005843 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:20:07] 0.018948 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:20:22] Energy consumed for RAM : 0.001253 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:20:22] Energy consumed for all GPUs : 0.012110 kWh. Total GPU Power : 56.50776245595433 W\n",
            "[codecarbon INFO @ 18:20:22] Energy consumed for all CPUs : 0.005958 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:20:22] 0.019321 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:20:37] Energy consumed for RAM : 0.001277 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:20:37] Energy consumed for all GPUs : 0.012346 kWh. Total GPU Power : 56.57263523412316 W\n",
            "[codecarbon INFO @ 18:20:37] Energy consumed for all CPUs : 0.006072 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:20:37] 0.019695 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:20:52] Energy consumed for RAM : 0.001301 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:20:52] Energy consumed for all GPUs : 0.012574 kWh. Total GPU Power : 54.90490577047683 W\n",
            "[codecarbon INFO @ 18:20:52] Energy consumed for all CPUs : 0.006187 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:20:52] 0.020062 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:21:07] Energy consumed for RAM : 0.001325 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:21:07] Energy consumed for all GPUs : 0.012809 kWh. Total GPU Power : 56.42055169831236 W\n",
            "[codecarbon INFO @ 18:21:07] Energy consumed for all CPUs : 0.006301 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:21:07] 0.020436 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:21:22] Energy consumed for RAM : 0.001349 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:21:22] Energy consumed for all GPUs : 0.013039 kWh. Total GPU Power : 55.24092968163405 W\n",
            "[codecarbon INFO @ 18:21:22] Energy consumed for all CPUs : 0.006416 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:21:22] 0.020805 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:21:37] Energy consumed for RAM : 0.001373 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:21:37] Energy consumed for all GPUs : 0.013272 kWh. Total GPU Power : 55.90096182148766 W\n",
            "[codecarbon INFO @ 18:21:37] Energy consumed for all CPUs : 0.006531 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:21:37] 0.021176 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:21:52] Energy consumed for RAM : 0.001397 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:21:52] Energy consumed for all GPUs : 0.013508 kWh. Total GPU Power : 56.70090956296634 W\n",
            "[codecarbon INFO @ 18:21:52] Energy consumed for all CPUs : 0.006645 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:21:52] 0.021551 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:22:07] Energy consumed for RAM : 0.001422 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:22:07] Energy consumed for all GPUs : 0.013743 kWh. Total GPU Power : 56.40392115742836 W\n",
            "[codecarbon INFO @ 18:22:07] Energy consumed for all CPUs : 0.006760 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:22:07] 0.021924 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:22:22] Energy consumed for RAM : 0.001446 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:22:22] Energy consumed for all GPUs : 0.013986 kWh. Total GPU Power : 58.38197015489984 W\n",
            "[codecarbon INFO @ 18:22:22] Energy consumed for all CPUs : 0.006874 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:22:22] 0.022306 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:22:37] Energy consumed for RAM : 0.001470 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:22:37] Energy consumed for all GPUs : 0.014222 kWh. Total GPU Power : 56.86762741794108 W\n",
            "[codecarbon INFO @ 18:22:37] Energy consumed for all CPUs : 0.006989 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:22:37] 0.022681 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:22:52] Energy consumed for RAM : 0.001494 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:22:52] Energy consumed for all GPUs : 0.014462 kWh. Total GPU Power : 57.42706075970111 W\n",
            "[codecarbon INFO @ 18:22:52] Energy consumed for all CPUs : 0.007104 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:22:52] 0.023059 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:23:07] Energy consumed for RAM : 0.001518 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:23:07] Energy consumed for all GPUs : 0.014699 kWh. Total GPU Power : 57.17695314365385 W\n",
            "[codecarbon INFO @ 18:23:07] Energy consumed for all CPUs : 0.007218 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:23:07] 0.023435 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:23:22] Energy consumed for RAM : 0.001542 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:23:22] Energy consumed for all GPUs : 0.014937 kWh. Total GPU Power : 56.922337133914944 W\n",
            "[codecarbon INFO @ 18:23:22] Energy consumed for all CPUs : 0.007333 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:23:22] 0.023811 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:23:37] Energy consumed for RAM : 0.001566 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:23:37] Energy consumed for all GPUs : 0.015173 kWh. Total GPU Power : 56.98213688784802 W\n",
            "[codecarbon INFO @ 18:23:37] Energy consumed for all CPUs : 0.007447 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:23:37] 0.024187 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:23:52] Energy consumed for RAM : 0.001590 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:23:52] Energy consumed for all GPUs : 0.015413 kWh. Total GPU Power : 57.52754064166802 W\n",
            "[codecarbon INFO @ 18:23:52] Energy consumed for all CPUs : 0.007562 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:23:52] 0.024565 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:24:07] Energy consumed for RAM : 0.001614 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:24:07] Energy consumed for all GPUs : 0.015641 kWh. Total GPU Power : 54.720535376200004 W\n",
            "[codecarbon INFO @ 18:24:07] Energy consumed for all CPUs : 0.007676 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:24:07] 0.024931 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:24:22] Energy consumed for RAM : 0.001638 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:24:22] Energy consumed for all GPUs : 0.015875 kWh. Total GPU Power : 56.1752068444011 W\n",
            "[codecarbon INFO @ 18:24:22] Energy consumed for all CPUs : 0.007791 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:24:22] 0.025304 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:24:37] Energy consumed for RAM : 0.001663 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:24:37] Energy consumed for all GPUs : 0.016108 kWh. Total GPU Power : 55.895264741145226 W\n",
            "[codecarbon INFO @ 18:24:37] Energy consumed for all CPUs : 0.007905 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:24:37] 0.025675 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:24:52] Energy consumed for RAM : 0.001687 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:24:52] Energy consumed for all GPUs : 0.016347 kWh. Total GPU Power : 57.418050042290126 W\n",
            "[codecarbon INFO @ 18:24:52] Energy consumed for all CPUs : 0.008020 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:24:52] 0.026053 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:25:07] Energy consumed for RAM : 0.001711 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:25:07] Energy consumed for all GPUs : 0.016582 kWh. Total GPU Power : 56.48887399188846 W\n",
            "[codecarbon INFO @ 18:25:07] Energy consumed for all CPUs : 0.008135 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:25:07] 0.026427 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:25:22] Energy consumed for RAM : 0.001735 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:25:22] Energy consumed for all GPUs : 0.016815 kWh. Total GPU Power : 55.956730608744 W\n",
            "[codecarbon INFO @ 18:25:22] Energy consumed for all CPUs : 0.008249 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:25:22] 0.026799 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:25:37] Energy consumed for RAM : 0.001759 kWh. RAM Power : 5.789747714996338 W\n",
            "[codecarbon INFO @ 18:25:37] Energy consumed for all GPUs : 0.017054 kWh. Total GPU Power : 57.5597664658559 W\n",
            "[codecarbon INFO @ 18:25:37] Energy consumed for all CPUs : 0.008364 kWh. Total CPU Power : 27.5 W\n",
            "[codecarbon INFO @ 18:25:37] 0.027177 kWh of electricity used since the beginning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, _, _ = trainer.predict(validation_dataset)\n",
        "start_logits, end_logits = predictions\n",
        "compute_metrics(start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"])"
      ],
      "metadata": {
        "id": "HwdQwTRXO3fj"
      },
      "id": "HwdQwTRXO3fj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cumulator.off()\n",
        "cumulator.on()"
      ],
      "metadata": {
        "id": "FQ7AdGE05tjk"
      },
      "id": "FQ7AdGE05tjk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cumulator.display_carbon_footprint()"
      ],
      "metadata": {
        "id": "06x1ToXR7yQM"
      },
      "id": "06x1ToXR7yQM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message=\"Training complete\")"
      ],
      "metadata": {
        "id": "ypfEyrVvUvKE"
      },
      "id": "ypfEyrVvUvKE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator, DataCollatorForLanguageModeling\n",
        "\n",
        "train_dataset.set_format(\"torch\")\n",
        "validation_set = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
        "validation_set.set_format(\"torch\")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    collate_fn=default_data_collator,\n",
        "    batch_size=8,\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    validation_set,\n",
        "    collate_fn=default_data_collator,\n",
        "    batch_size=8\n",
        ")"
      ],
      "metadata": {
        "id": "yuJHm9tvUw3E"
      },
      "id": "yuJHm9tvUw3E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "MIBcgD0DU5XA"
      },
      "id": "MIBcgD0DU5XA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")"
      ],
      "metadata": {
        "id": "8P6aY73FU69i"
      },
      "id": "8P6aY73FU69i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_train_epochs = 3\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "JyE-kIfDU9cn"
      },
      "id": "JyE-kIfDU9cn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import Repository, get_full_repo_name\n",
        "model_name = \"no-pretraining-bert-final\"\n",
        "repo_name = get_full_repo_name(model_name)\n",
        "repo_name"
      ],
      "metadata": {
        "id": "3nfQA8p9P3vx"
      },
      "id": "3nfQA8p9P3vx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import Repository\n",
        "model_checkpoint = 'no-pretraining-bert-final'\n",
        "output_dir = \"no-pretraining-bert-final-accelerate\" + model_checkpoint\n",
        "\n",
        "repo = Repository(output_dir, clone_from=repo_name)"
      ],
      "metadata": {
        "id": "utLyR3CAayat"
      },
      "id": "utLyR3CAayat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finetune cycle\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    start_logits = []\n",
        "    end_logits = []\n",
        "    accelerator.print(\"Evaluation!\")\n",
        "    for batch in tqdm(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())\n",
        "        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())\n",
        "\n",
        "    start_logits = np.concatenate(start_logits)\n",
        "    end_logits = np.concatenate(end_logits)\n",
        "    start_logits = start_logits[: len(validation_dataset)]\n",
        "    end_logits = end_logits[: len(validation_dataset)]\n",
        "\n",
        "    metrics = compute_metrics(\n",
        "        start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"]\n",
        "    )\n",
        "\n",
        "    for key, value in metrics.items():\n",
        "        experiment.log_metric(key, value)\n",
        "\n",
        "    print(f\"epoch {epoch}:\", metrics)\n",
        "\n",
        "    # Save and upload\n",
        "    accelerator.wait_for_everyone()\n",
        "    unwrapped_model = accelerator.unwrap_model(model)\n",
        "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
        "    if accelerator.is_main_process:\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "        repo.push_to_hub(\n",
        "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
        "        )"
      ],
      "metadata": {
        "id": "wRGHfth65kfG"
      },
      "id": "wRGHfth65kfG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerator.wait_for_everyone()\n",
        "unwrapped_model = accelerator.unwrap_model(model)\n",
        "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
      ],
      "metadata": {
        "id": "IE6Fknm6pz_C"
      },
      "id": "IE6Fknm6pz_C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment.end()"
      ],
      "metadata": {
        "id": "Lm8oRHkfG2bF"
      },
      "id": "Lm8oRHkfG2bF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cumulator.off()\n",
        "cumulator.display_carbon_footprint()"
      ],
      "metadata": {
        "id": "GJ2vcZFb5zYA"
      },
      "id": "GJ2vcZFb5zYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cumulator.time_list"
      ],
      "metadata": {
        "id": "N9OsIydK59i7"
      },
      "id": "N9OsIydK59i7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc830f96003a4801a571b0752a571376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90a62df70c2d43c4b39c610d734cadb5",
              "IPY_MODEL_d21f8f3689ff47d1b8649c504c47fb15",
              "IPY_MODEL_47af879a7b01421590211561f8bb39bd",
              "IPY_MODEL_17885cd373c64cfa8010894bd6fc7b54"
            ],
            "layout": "IPY_MODEL_1aa06dcace3345ea9f892b5a7f6fd676"
          }
        },
        "7e65103e979440779408089b600c7d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e337e209c914018838269dcfbe70f5b",
            "placeholder": "​",
            "style": "IPY_MODEL_618d0fe8ff38410996e259da236995c7",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "7adf6cba500a42f69da4c65b09edaa88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_2d59618622fa46f3a04984adf84aba4a",
            "placeholder": "​",
            "style": "IPY_MODEL_6767bb2f358c461ca28d456434499bda",
            "value": ""
          }
        },
        "97342f20101a4680adfcbe475b07094c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7f3d09f203e54ddab5b42ef18fbd7a44",
            "style": "IPY_MODEL_3f54bfec11804ba187edc7274508fb34",
            "value": true
          }
        },
        "ccfdb40506cb4088addfc4ac85a7e9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_aba9a497813947e3a04ba63cac9d9cd4",
            "style": "IPY_MODEL_3f78d60b76e447d384090c0df459dbdf",
            "tooltip": ""
          }
        },
        "650976b77f0748578d57351a03857f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a61980996b7e40dfbb12417289ba6aee",
            "placeholder": "​",
            "style": "IPY_MODEL_a193cc403e8e4838aedfef3ec1dea15e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "1aa06dcace3345ea9f892b5a7f6fd676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3e337e209c914018838269dcfbe70f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618d0fe8ff38410996e259da236995c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d59618622fa46f3a04984adf84aba4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6767bb2f358c461ca28d456434499bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f3d09f203e54ddab5b42ef18fbd7a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f54bfec11804ba187edc7274508fb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba9a497813947e3a04ba63cac9d9cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f78d60b76e447d384090c0df459dbdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a61980996b7e40dfbb12417289ba6aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a193cc403e8e4838aedfef3ec1dea15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc5e9512dbc7472b979ec72f37e50d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c0230e4a8714e46bb0d3a6de99f355d",
            "placeholder": "​",
            "style": "IPY_MODEL_93414c8a2dc54c8fa1471c1ced4df716",
            "value": "Connecting..."
          }
        },
        "4c0230e4a8714e46bb0d3a6de99f355d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93414c8a2dc54c8fa1471c1ced4df716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90a62df70c2d43c4b39c610d734cadb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a06672a36a4419a86c2a17616a1cd60",
            "placeholder": "​",
            "style": "IPY_MODEL_d4b2d18650814ce69405b6e7aebfd618",
            "value": "Token is valid (permission: write)."
          }
        },
        "d21f8f3689ff47d1b8649c504c47fb15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc67173be16843a7b51ddfa40db395be",
            "placeholder": "​",
            "style": "IPY_MODEL_3fcd6cf09b634d588a1160d07e7b4385",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "47af879a7b01421590211561f8bb39bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab661f346b944ef8ffa2c4491911c92",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc5555120ca4c9e9796b630a2ba4192",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "17885cd373c64cfa8010894bd6fc7b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b46e1b7d44c740c0a484bbbcc9ec9c4c",
            "placeholder": "​",
            "style": "IPY_MODEL_189272fae1a248a8a6d1f09515cf598a",
            "value": "Login successful"
          }
        },
        "9a06672a36a4419a86c2a17616a1cd60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4b2d18650814ce69405b6e7aebfd618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc67173be16843a7b51ddfa40db395be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fcd6cf09b634d588a1160d07e7b4385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ab661f346b944ef8ffa2c4491911c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc5555120ca4c9e9796b630a2ba4192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b46e1b7d44c740c0a484bbbcc9ec9c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189272fae1a248a8a6d1f09515cf598a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e262e17666147aebd4731e391cfcbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6b0a6d43f214d589470c43d20b0ecd6",
              "IPY_MODEL_2dab8c5fa2b74875b0171c69fbabdd80",
              "IPY_MODEL_04ef4c9dd0064c50962f40f332fb571e"
            ],
            "layout": "IPY_MODEL_9e5fb55c2f044a33b15241e15cc9c2a4"
          }
        },
        "c6b0a6d43f214d589470c43d20b0ecd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_398c855f74b64eb884bc3ecacf02145f",
            "placeholder": "​",
            "style": "IPY_MODEL_ae09a1d8d10e40ab988ec43c7da930ce",
            "value": "Map: 100%"
          }
        },
        "2dab8c5fa2b74875b0171c69fbabdd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acad1940248e43e788d3edf8136d031a",
            "max": 87599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e6b7cb3a70340618bcd640f68902af3",
            "value": 87599
          }
        },
        "04ef4c9dd0064c50962f40f332fb571e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1fd21b234d340979cecc0751984deeb",
            "placeholder": "​",
            "style": "IPY_MODEL_c62c134d40eb45459d1878fd5d703c3d",
            "value": " 87599/87599 [00:21&lt;00:00, 4349.44 examples/s]"
          }
        },
        "9e5fb55c2f044a33b15241e15cc9c2a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "398c855f74b64eb884bc3ecacf02145f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae09a1d8d10e40ab988ec43c7da930ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acad1940248e43e788d3edf8136d031a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6b7cb3a70340618bcd640f68902af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1fd21b234d340979cecc0751984deeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c62c134d40eb45459d1878fd5d703c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2e7efd8de30429eb9da4bfe99d62d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_210416c6a771448fbb0a8bf2bcb86436",
              "IPY_MODEL_1016fe89187944db914f82c742e49409",
              "IPY_MODEL_ed14e8cf3e0c42ad921e740a2ef82637"
            ],
            "layout": "IPY_MODEL_1615915542444c24ac0c9f25a2540297"
          }
        },
        "210416c6a771448fbb0a8bf2bcb86436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11c24520e5e34ae29fcc8d79d9be5410",
            "placeholder": "​",
            "style": "IPY_MODEL_d7cd1949f78f47cf859f0a2a65e36989",
            "value": "Map: 100%"
          }
        },
        "1016fe89187944db914f82c742e49409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872d386ea4f84b86b39b4b854c90ab0a",
            "max": 10570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_587beabd25734baf8cdbc1c73e152595",
            "value": 10570
          }
        },
        "ed14e8cf3e0c42ad921e740a2ef82637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab51f3d150d4eafa38d731c0ff61f39",
            "placeholder": "​",
            "style": "IPY_MODEL_e301d552b438487abac84e49a059dcf4",
            "value": " 10570/10570 [00:03&lt;00:00, 2843.74 examples/s]"
          }
        },
        "1615915542444c24ac0c9f25a2540297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c24520e5e34ae29fcc8d79d9be5410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7cd1949f78f47cf859f0a2a65e36989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "872d386ea4f84b86b39b4b854c90ab0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "587beabd25734baf8cdbc1c73e152595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ab51f3d150d4eafa38d731c0ff61f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e301d552b438487abac84e49a059dcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}